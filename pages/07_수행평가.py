import streamlit as st
import pandas as pd
import plotly.express as px
import datetime
from pathlib import Path

# ---------- Config ----------
st.set_page_config(page_title="ë””ì €íŠ¸ íŠ¸ë Œë“œ & ì¹´í˜ ì¶”ì²œ", layout="wide")
BASE_PATH = Path("/mnt/data")
DESSERT_CSV = BASE_PATH / "DESSERT.csv.csv"
CAFE_CSV = BASE_PATH / "CAFE.csv.csv"

# ---------- Styling (beige / brown) ----------
st.markdown(
    """
    <style>
    .stApp {
        background: linear-gradient(180deg, #F7EFE6 0%, #E9DCC9 100%);
        color: #3E2723;
    }
    .sidebar .sidebar-content {
        background: #E7D4BF;
    }
    .stButton>button {
        background-color: #8D6E63;
        color: white;
    }
    .big-title {
        font-size:32px;
        font-weight:700;
        color:#4E342E;
    }
    .muted {
        color:#5D4037;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

st.markdown('<div class="big-title">ğŸ° ë””ì €íŠ¸ íŠ¸ë Œë“œ íƒìƒ‰ & ì¹´í˜ ì¶”ì²œ</div>', unsafe_allow_html=True)
st.markdown("ì„ íƒí•œ ê¸°ê°„ ë‚´ì— ë””ì €íŠ¸ê°€ ì–¼ë§ˆë‚˜ ê²€ìƒ‰(ì–¸ê¸‰)ë˜ì—ˆëŠ”ì§€ ì‹œê°í™”í•˜ê³ , í•´ë‹¹ ë””ì €íŠ¸ë¥¼ íŒë§¤í•˜ëŠ” ì¹´í˜ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤. (UI ìƒ‰ìƒì€ ì¹´í˜ ë¶„ìœ„ê¸° â€” ë² ì´ì§€/ê°ˆìƒ‰ ê³„ì—´)")

# ---------- Helpers to detect columns ----------
def detect_date_column(df):
    for c in df.columns:
        lc = c.lower()
        if "date" in lc or "day" in lc or "time" in lc:
            return c
    # fallback: first datetime-like column
    for c in df.columns:
        try:
            pd.to_datetime(df[c])
            return c
        except Exception:
            continue
    return None

def detect_count_column(df):
    # common names
    for c in df.columns:
        lc = c.lower()
        if any(x in lc for x in ["count","search","mentions","value","hits","freq","frequency"]):
            return c
    # fallback numeric column (excluding obvious id columns)
    numeric_cols = df.select_dtypes(include=["number"]).columns.tolist()
    if numeric_cols:
        return numeric_cols[0]
    return None

# ---------- Load data ----------
@st.cache_data
def load_csv(path):
    try:
        df = pd.read_csv(path)
        return df
    except Exception as e:
        st.error(f"íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {path}\\nì—ëŸ¬: {e}")
        return None

dessert_df = load_csv(DESSERT_CSV)
cafe_df = load_csv(CAFE_CSV)

if dessert_df is None:
    st.stop()

# ---------- Analyze DESSERT.csv ----------
st.header("1) DESSERT.csv ë°ì´í„° í™•ì¸")
st.write("íŒŒì¼ ê²½ë¡œ:", str(DESSERT_CSV))
st.write("ê¸°ë³¸ ì •ë³´:")
st.write(f"- í–‰: {len(dessert_df)}, ì—´: {len(dessert_df.columns)}")
st.dataframe(dessert_df.head(10))

date_col = detect_date_column(dessert_df)
count_col = detect_count_column(dessert_df)
dessert_col = None
for c in dessert_df.columns:
    if "dessert" in c.lower() or "name" in c.lower() or "item" in c.lower():
        dessert_col = c
        break
# fallback: try to find a column with few unique values and string type (likely dessert names)
if dessert_col is None:
    string_cols = dessert_df.select_dtypes(include=["object"]).columns.tolist()
    for c in string_cols:
        if 1 < dessert_df[c].nunique() < max(50, len(dessert_df)//5):
            dessert_col = c
            break

if date_col is None or dessert_col is None or count_col is None:
    st.warning("íŒŒì¼ì—ì„œ ì£¼ìš” ì»¬ëŸ¼(ë‚ ì§œ, ë””ì €íŠ¸ëª…, ì¹´ìš´íŠ¸)ì„ ìë™ìœ¼ë¡œ ì°¾ì§€ ëª»í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ ì„ íƒ ë°•ìŠ¤ë¡œ ìˆ˜ë™ ì§€ì •í•˜ì„¸ìš”.")
    col1, col2, col3 = st.columns(3)
    with col1:
        date_col = st.selectbox("ë‚ ì§œ ì»¬ëŸ¼ ì„ íƒ", ["(ìë™íƒì§€ ì‹¤íŒ¨)"] + list(dessert_df.columns), index=0 if date_col is None else list(dessert_df.columns).index(date_col)+1)
    with col2:
        dessert_col = st.selectbox("ë””ì €íŠ¸ ì´ë¦„ ì»¬ëŸ¼ ì„ íƒ", ["(ìë™íƒì§€ ì‹¤íŒ¨)"] + list(dessert_df.columns), index=0 if dessert_col is None else list(dessert_df.columns).index(dessert_col)+1)
    with col3:
        count_col = st.selectbox("ê²€ìƒ‰ìˆ˜/ì¹´ìš´íŠ¸ ì»¬ëŸ¼ ì„ íƒ", ["(ìë™íƒì§€ ì‹¤íŒ¨)"] + list(dessert_df.columns), index=0 if count_col is None else list(dessert_df.columns).index(count_col)+1)

# Try to parse dates
try:
    dessert_df[date_col] = pd.to_datetime(dessert_df[date_col])
except Exception:
    st.error(f"ì„ íƒí•œ ë‚ ì§œ ì»¬ëŸ¼({date_col})ì„ ë‚ ì§œë¡œ ë³€í™˜í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë°ì´í„° í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# Sidebar UI: dessert & date range
st.sidebar.header("ê²€ìƒ‰ ì¡°ê±´")
desserts_unique = sorted(dessert_df[dessert_col].dropna().astype(str).unique())
selected_dessert = st.sidebar.selectbox("ë””ì €íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”", desserts_unique)
min_date = dessert_df[date_col].min().date()
max_date = dessert_df[date_col].max().date()
default_start = max_date - datetime.timedelta(days=30)
selected_range = st.sidebar.date_input("ê¸°ê°„ ì„ íƒ (ì‹œì‘, ì¢…ë£Œ)", value=(default_start, max_date), min_value=min_date, max_value=max_date)

if len(selected_range) != 2:
    st.error("ê¸°ê°„ì€ ì‹œì‘ê³¼ ì¢…ë£Œ, ë‘ ë‚ ì§œë¥¼ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
    st.stop()
start_date, end_date = selected_range
start_dt = pd.to_datetime(start_date)
end_dt = pd.to_datetime(end_date) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)

# Filter data
mask = (dessert_df[date_col] >= start_dt) & (dessert_df[date_col] <= end_dt) & (dessert_df[dessert_col].astype(str) == str(selected_dessert))
filtered = dessert_df.loc[mask].copy()
st.subheader(f"ì„ íƒ: {selected_dessert} â€” {start_date} ë¶€í„° {end_date} ê¹Œì§€")
st.write(f"ê¸°ê°„ ë‚´ ì´ ê´€ì¸¡ì¹˜: {len(filtered)}")

if len(filtered) == 0:
    st.info("ì„ íƒí•œ ê¸°ê°„/ë””ì €íŠ¸ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ë””ì €íŠ¸ íŠ¸ë Œë“œë¥¼ ëŒ€ì‹  ë³´ì—¬ë“œë¦½ë‹ˆë‹¤.")
    # show aggregated trend for that dessert name across all dates
    agg = dessert_df.groupby(pd.Grouper(key=date_col, freq="D"))[count_col].sum().reset_index()
else:
    agg = filtered.groupby(pd.Grouper(key=date_col, freq="D"))[count_col].sum().reset_index()

# Fill missing days
agg = agg.set_index(date_col).asfreq("D", fill_value=0).reset_index()

# Plot with plotly
st.header("2) íŠ¸ë Œë“œ ê·¸ë˜í”„ (Plotly)")
fig = px.line(agg, x=date_col, y=count_col, title=f"{selected_dessert} ê²€ìƒ‰ëŸ‰ ì¶”ì´", markers=True)
fig.update_layout(template="plotly_white",
                  plot_bgcolor="rgba(0,0,0,0)",
                  paper_bgcolor="rgba(0,0,0,0)",
                  xaxis_title="ë‚ ì§œ",
                  yaxis_title="ê²€ìƒ‰ ìˆ˜ / ì–¸ê¸‰ ìˆ˜")
st.plotly_chart(fig, use_container_width=True)

# Simple stats
st.header("3) ê°„ë‹¨ í†µê³„")
col_a, col_b, col_c = st.columns(3)
with col_a:
    st.metric("ê¸°ê°„ í•©ê³„", int(agg[count_col].sum()))
with col_b:
    st.metric("í‰ê· (ì¼)", round(float(agg[count_col].mean()),2))
with col_c:
    st.metric("ìµœëŒ€ê°’(ì¼)", int(agg[count_col].max()))

# ---------- CAFE.csv analysis ----------
st.header("4) CAFE.csv ë°ì´í„° í™•ì¸")
if cafe_df is None:
    st.warning("CAFE.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì¶”ì²œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    cafe_df = pd.DataFrame()
else:
    st.write("íŒŒì¼ ê²½ë¡œ:", str(CAFE_CSV))
    st.write("ê¸°ë³¸ ì •ë³´:")
    st.write(f"- í–‰: {len(cafe_df)}, ì—´: {len(cafe_df.columns)}")
    st.dataframe(cafe_df.head(10))

# Ask user if they'd like recommendations
st.header("5) ì¹´í˜ ì¶”ì²œ")
want_reco = st.radio("ì„ íƒí•œ ë””ì €íŠ¸ë¥¼ íŒë§¤í•˜ëŠ” ì¹´í˜ë¥¼ ì¶”ì²œí•´ë“œë¦´ê¹Œìš”?", ("Yes", "No"))

if want_reco == "No":
    st.info("ìš”ì²­í•˜ì‹  ëŒ€ë¡œ ì¹´í˜ ì¶”ì²œì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ë””ì €íŠ¸/ê¸°ê°„ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
else:
    if cafe_df is None or cafe_df.empty:
        st.warning("CAFE.csv ë°ì´í„°ê°€ ì—†ì–´ì„œ ì¶”ì²œì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # Try to find cafe columns
        cafe_name_col = None
        cafe_menu_col = None
        cafe_addr_col = None
        cafe_score_col = None
        for c in cafe_df.columns:
            lc = c.lower()
            if any(x in lc for x in ["name","cafe","shop"]):
                cafe_name_col = cafe_name_col or c
            if any(x in lc for x in ["menu","dessert","items","product"]):
                cafe_menu_col = cafe_menu_col or c
            if any(x in lc for x in ["addr","address","location","place"]):
                cafe_addr_col = cafe_addr_col or c
            if any(x in lc for x in ["score","rating","rate","stars"]):
                cafe_score_col = cafe_score_col or c

        # fallback defaults
        if cafe_name_col is None:
            cafe_name_col = cafe_df.columns[0]
        if cafe_menu_col is None:
            # try a string column with many unique values
            for c in cafe_df.select_dtypes(include=["object"]).columns:
                if cafe_df[c].astype(str).str.contains(str(selected_dessert), case=False).any():
                    cafe_menu_col = c
                    break
            if cafe_menu_col is None:
                cafe_menu_col = cafe_df.select_dtypes(include=["object"]).columns[0] if len(cafe_df.columns)>0 else None

        # Filter cafes that mention the dessert (case-insensitive substring match)
        mask_cafe = cafe_df[cafe_menu_col].astype(str).str.contains(str(selected_dessert), case=False, na=False)
        matches = cafe_df.loc[mask_cafe].copy()
        if matches.empty:
            st.info("ë°ì´í„°ì—ì„œ í•´ë‹¹ ë””ì €íŠ¸ë¥¼ íŒë§¤í•˜ëŠ” ì¹´í˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (CAFE.csvì˜ ë©”ë‰´/ì„¤ëª… ì»¬ëŸ¼ì„ í™•ì¸í•˜ì„¸ìš”)")
        else:
            # Sort by score if exists
            if cafe_score_col and cafe_score_col in matches.columns:
                try:
                    matches[cafe_score_col] = pd.to_numeric(matches[cafe_score_col], errors="coerce")
                    matches = matches.sort_values(by=cafe_score_col, ascending=False)
                except Exception:
                    pass

            st.subheader(f"'{selected_dessert}'ì„(ë¥¼) íŒë§¤í•˜ëŠ” ì¹´í˜ ì¶”ì²œ ({len(matches)}ê³³)")
            display_cols = [c for c in [cafe_name_col, cafe_menu_col, cafe_addr_col, cafe_score_col] if c and c in matches.columns]
            st.dataframe(matches[display_cols].reset_index(drop=True))

            # Show map if lat/lon columns exist
            lat_col = None
            lon_col = None
            for c in matches.columns:
                if "lat" in c.lower():
                    lat_col = c
                if "lon" in c.lower() or "lng" in c.lower():
                    lon_col = c
            if lat_col and lon_col:
                st.subheader("ìœ„ì¹˜ ì§€ë„")
                try:
                    map_df = matches[[lat_col, lon_col]].dropna()
                    map_df = map_df.rename(columns={lat_col:"lat", lon_col:"lon"})
                    st.map(map_df)
                except Exception:
                    pass

st.markdown("---")
st.markdown("ì•± ì œì‘ì: ìë™ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ â€¢ ìƒ‰ìƒ í…Œë§ˆ: ë² ì´ì§€/ê°ˆìƒ‰")
